{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"id":"QnTZccLkU0PJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656676869750,"user_tz":-240,"elapsed":5149,"user":{"displayName":"Andrey Andrey","userId":"10427328636042614556"}},"outputId":"b262de67-04a7-4496-c17d-eb2e636d8b7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/CS231N/assignments/assignment2/cs231n/datasets\n","/content\n"]}],"source":["# this mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# enter the foldername in your Drive where you have saved the unzipped\n","# assignment folder, e.g. 'cs231n/assignments/assignment3/'\n","FOLDERNAME = \"CS231N/assignments/assignment2/\"\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# now that we've mounted your Drive, this ensures that\n","# the Python interpreter of the Colab VM can load\n","# python files from within it.\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","\n","# this downloads the CIFAR-10 dataset to your Drive\n","# if it doesn't already exist.\n","%cd drive/My\\ Drive/$FOLDERNAME/cs231n/datasets/\n","!bash get_datasets.sh\n","%cd /content"]},{"cell_type":"markdown","metadata":{"tags":["pdf-title"],"id":"AvTbka3TU0PO"},"source":["# What's this PyTorch business?\n","\n","Вы написали много кода в этом задании, чтобы обеспечить целый ряд функций нейронной сети. Dropout, Batch Norm и 2D-свертки являются одними из рабочих лошадок глубокого обучения в компьютерном зрении. Вы также усердно работали над тем, чтобы сделать ваш код эффективным и векторизованным. \n","\n","Однако в последней части этого задания мы собираемся оставить вашу прекрасную кодовую базу и вместо этого перейти к одной из двух популярных сред глубокого обучения: в данном случае PyTorch (или TensorFlow, если вы решите использовать этот блокнот)."]},{"cell_type":"markdown","metadata":{"tags":["pdf-ignore"],"id":"p4puvLyOU0PQ"},"source":["### What is PyTorch?\n","\n","PyTorch — это система для выполнения динамических вычислительных графов над объектами Tensor, которые ведут себя аналогично numpy ndarray. Он поставляется с мощным механизмом автоматической дифференциации, который устраняет необходимость в ручном обратном распространении.\n","\n","### Why?\n","\n","* Наш код теперь будет работать на GPU! Гораздо быстрее обучение. При использовании таких фреймворков, как PyTorch или TensorFlow, вы можете использовать мощь графического процессора для своих собственных архитектур нейронных сетей без необходимости напрямую писать код CUDA (что выходит за рамки этого класса). \n","* Мы хотим, чтобы вы были готовы использовать одну из этих платформ для своего проекта, чтобы вы могли экспериментировать более эффективно, чем если бы вы писали каждую функцию, которую хотите использовать, вручную. \n","* Мы хотим, чтобы вы стояли на плечах гигантов! TensorFlow и PyTorch — отличные фреймворки, которые сделают вашу жизнь намного проще, и теперь, когда вы понимаете их суть, вы можете свободно их использовать :) \n","* Мы хотим, чтобы вы познакомились с кодом глубокого обучения, с которым вы можете столкнуться в академии или промышленности.\n","\n","### PyTorch versions\n","В этой записной книжке предполагается, что вы используете **PyTorch версии 1.4**. В некоторых предыдущих версиях (например, до 0.4) тензоры должны были быть заключены в объекты Variable для использования в autograd; однако переменные теперь устарели. Кроме того, версии 1.0+ отделяют тип данных тензора от его устройства и используют фабрики в стиле numpy для создания тензоров, а не напрямую вызывают конструкторы тензора."]},{"cell_type":"markdown","metadata":{"tags":["pdf-ignore"],"id":"aHBJroPbU0PS"},"source":["## How will I learn PyTorch?\n","\n","\n","Justin Johnson сделал отличный [учебник](https://github.com/jcjohnson/pytorch-examples) для PyTorch. \n","\n","Вы также можете найти подробную [документацию по API](http://pytorch.org/docs/stable/index.html) здесь. Если у вас есть другие вопросы, которые не рассматриваются в документации API, [форум PyTorch](https://discuss.pytorch.org/) — гораздо лучшее место, чтобы задать их, чем StackOverflow.\n","\n","## Install PyTorch 1.4 (ONLY IF YOU ARE WORKING LOCALLY)\n","\n","1. Установите на свой компьютер последнюю версию Anaconda. \n","2. Создайте новую среду conda, начиная с Python 3.7. В этом примере настройки мы назовем его torch_env. \n","3. Запустите команду: `conda активировать torch_env` \n","4. Запустите команду: `pip install torch==1.4 torchvision==0.5.0`"]},{"cell_type":"markdown","metadata":{"id":"PQ7L6xtcU0PT"},"source":["# Table of Contents\n","\n","Это задание состоит из 5 частей. Вы изучите PyTorch на **трех разных уровнях абстракции**, что поможет вам лучше понять его и подготовить к финальному проекту. \n","\n","1. Часть I. Подготовка: мы будем использовать набор данных CIFAR-10. \n","2. Часть II, Barebones PyTorch: **Уровень абстракции 1**, мы будем работать непосредственно с тензорами PyTorch самого низкого уровня. \n","3. Часть III, API модуля PyTorch: **Уровень абстракции 2**, мы будем использовать `nn.Module` для определения произвольной архитектуры нейронной сети. \n","4. Часть IV, PyTorch Sequential API: **Уровень абстракции 3**, мы будем использовать `nn.Sequential` для очень удобного определения линейной сети прямой связи. \n","5. Часть V, открытое задание CIFAR-10: пожалуйста, создайте свою собственную сеть, чтобы получить максимально возможную точность на CIFAR-10. Вы можете экспериментировать с любым слоем, оптимизатором, гиперпараметрами или другими расширенными возможностями.\n","\n","Вот таблица сравнения:\n","\n","| API           | Flexibility | Convenience |\n","|---------------|-------------|-------------|\n","| Barebone      | High        | Low         |\n","| `nn.Module`     | High        | Medium      |\n","| `nn.Sequential` | Low         | High        |"]},{"cell_type":"markdown","metadata":{"id":"Xv3ZUl-ZU0PU"},"source":["# Part I. Preparation\n","\n","Сначала мы загружаем набор данных CIFAR-10. В первый раз это может занять пару минут, но после этого файлы должны оставаться в кэше. \n","\n","В предыдущих частях задания нам приходилось писать собственный код для загрузки набора данных CIFAR-10, его предварительной обработки и итерирования по нему в мини-пакетах; PyTorch предоставляет нам удобные инструменты для автоматизации этого процесса."]},{"cell_type":"code","execution_count":6,"metadata":{"tags":["pdf-ignore"],"id":"uUPhEe8fU0PV","executionInfo":{"status":"ok","timestamp":1656676869752,"user_tz":-240,"elapsed":15,"user":{"displayName":"Andrey Andrey","userId":"10427328636042614556"}}},"outputs":[],"source":["import torch\n","#assert '.'.join(torch.__version__.split('.')[:2]) == '1.4'\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torch.utils.data import sampler\n","\n","import torchvision.datasets as dset\n","import torchvision.transforms as T\n","\n","import numpy as np"]},{"cell_type":"code","execution_count":7,"metadata":{"tags":["pdf-ignore"],"id":"6GkVO-hqU0PW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656676873809,"user_tz":-240,"elapsed":4070,"user":{"displayName":"Andrey Andrey","userId":"10427328636042614556"}},"outputId":"fd9b024a-bcfb-4486-b396-41d1cbc80f64"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["NUM_TRAIN = 49000\n","\n","# Пакет torchvision.transforms предоставляет инструменты для предварительной обработки данных \n","# и выполнения аугментации данных; здесь мы настраиваем преобразование \n","# для предварительной обработки данных путем вычитания среднего значения RGB \n","# и деления на c.к.о. каждого значения RGB; \n","# мы жестко закодировали среднее значение и с.к.о.\n","\n","transform = T.Compose([\n","                T.ToTensor(),\n","                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","            ])\n","\n","# Настраиваем объект Dataset для каждого разделения (train/val/test); \n","# Наборы данных загружают обучающие примеры по одному, \n","# поэтому мы оборачиваем каждый набор данных в DataLoader, \n","# который перебирает набор данных и формирует мини-пакеты. \n","# Мы делим обучающий набор CIFAR-10 на наборы train и val, \n","# передавая объект Sampler в DataLoader, сообщая,\n","# как он должен выполнять выборку из базового набора данных.\n","\n","# эти множества train,val,test могут пересечься?\n","cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n","                             transform=transform)\n","loader_train = DataLoader(cifar10_train, batch_size=64, \n","                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n","\n","cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n","                           transform=transform)\n","loader_val = DataLoader(cifar10_val, batch_size=64, \n","                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n","\n","cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True, \n","                            transform=transform)\n","loader_test = DataLoader(cifar10_test, batch_size=64)"]},{"cell_type":"markdown","metadata":{"tags":["pdf-ignore"],"id":"c3jA203DU0PX"},"source":["У вас есть возможность **использовать GPU, установив флажок True ниже**. Для этого задания не обязательно использовать GPU. Обратите внимание, что если на вашем компьютере не включена CUDA, `torch.cuda.is_available()` вернет значение False, и этот блокнот вернется в режим ЦП. \n","\n","Глобальные переменные `dtype` и `device` будут управлять типами данных во всем этом задании.\n","\n","## Colab Users\n","\n","Если вы используете Colab, вам нужно вручную переключиться на устройство с графическим процессором. Вы можете сделать это, нажав `Runtime -> Change runtime type` и выбрав GPU под аппаратным ускорителем. Обратите внимание, что вам нужно повторно запускать ячейки сверху, так как ядро перезапускается при переключении сред выполнения.\n"]},{"cell_type":"code","execution_count":8,"metadata":{"tags":["pdf-ignore-input"],"id":"wB19-95hU0PY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656676873811,"user_tz":-240,"elapsed":11,"user":{"displayName":"Andrey Andrey","userId":"10427328636042614556"}},"outputId":"861db989-52d8-4b23-c44f-c049ae6ce225"},"outputs":[{"output_type":"stream","name":"stdout","text":["using device: cpu\n"]}],"source":["USE_GPU = True\n","\n","dtype = torch.float32 # we will be using float throughout this tutorial\n","\n","if USE_GPU and torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","\n","# Constant to control how frequently we print train loss\n","print_every = 100\n","\n","print('using device:', device)"]},{"cell_type":"markdown","metadata":{"id":"ACj5CxK8U0PZ"},"source":["# Part II. Barebones PyTorch\n","\n","PyTorch поставляется с высокоуровневыми API, которые помогают нам удобно определять архитектуры моделей, которые мы рассмотрим во второй части этого руководства. В этом разделе мы начнем с базовых элементов PyTorch, чтобы лучше понять движок autograd. После этого упражнения вы оцените высокоуровневый API моделей. \n","\n","Мы начнем с простой полносвязной сети ReLU с двумя скрытыми слоями и без смещений для классификации CIFAR. Эта реализация вычисляет прямой проход, используя операции с тензорами PyTorch, и использует автоградиент PyTorch для вычисления градиентов. Важно, чтобы вы понимали каждую строчку, потому что после примера вы напишете более сложную версию.\n","\n","\n","Когда мы создаем тензор PyTorch с `requires_grad=True`, тогда операции с этим тензором будут не просто вычислять значения; они также будут строить вычислительный граф в фоновом режиме, что позволит нам легко выполнить обратное распространение по графу для вычисления градиентов некоторых тензоров по отношению к потерям в нисходящем направлении. Конкретно, если x является тензором с `x.requires_grad == True`, то после обратного распространения `x.grad` будет другим тензором, содержащим градиент x относительно скалярной loss в конце."]},{"cell_type":"markdown","metadata":{"tags":["pdf-ignore"],"id":"iEyqJMHtU0PZ"},"source":["### PyTorch Tensors: Flatten Function\n","\n","\n","Тензор PyTorch концептуально похож на массив numpy: это n-мерная сетка чисел, и, как и numpy, PyTorch предоставляет множество функций для эффективной работы с тензорами. В качестве простого примера мы приводим ниже функцию  `flatten` , которая изменяет форму данных изображения для использования в полносвязной нейронной сети.\n","\n","Напомним, что данные изображения обычно хранятся в тензоре формы N x C x H x W, где: \n","\n","* N — количество точек данных \n","* C — количество каналов \n","* H — высота промежуточной карты признаков в пикселях \n","* W высота промежуточной карты признаков в пикселях\n","\n","Это правильный способ представления данных, когда мы делаем что-то вроде 2D-свертки, для которой требуется пространственное понимание того, где промежуточные признаки относятся друг к другу. Однако, когда мы используем полностью связанные аффинные слои для обработки изображения, мы хотим, чтобы каждая точка данных была представлена одним вектором — больше нет смысла разделять различные каналы, строки и столбцы данных. Итак, мы используем операцию 'сгладить' (flatten), чтобы схлопнуть значения `C x H x W` для каждого представления в один длинный вектор. Приведенная ниже функция flatten сначала считывает значения N, C, H и W из заданного пакета данных, а затем возвращает «представление» (view) этих данных. «View» аналогичен методу «изменить форму» (reshape) numpy: он изменяет размеры x на N x ??, где ?? может быть любым (в данном случае это будет C x H x W, но нам не нужно указывать это явно)."]},{"cell_type":"code","execution_count":17,"metadata":{"tags":["pdf-ignore-input"],"id":"YKo4KbuoU0Pa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656678361933,"user_tz":-240,"elapsed":408,"user":{"displayName":"Andrey Andrey","userId":"10427328636042614556"}},"outputId":"2211b1dc-84a7-470b-969c-a842e13c5576"},"outputs":[{"output_type":"stream","name":"stdout","text":["Before flattening:  tensor([[[[ 0,  1],\n","          [ 2,  3],\n","          [ 4,  5]]],\n","\n","\n","        [[[ 6,  7],\n","          [ 8,  9],\n","          [10, 11]]]])\n","After flattening:  tensor([[ 0,  1,  2,  3,  4,  5],\n","        [ 6,  7,  8,  9, 10, 11]])\n"]}],"source":["def flatten(x):\n","    N = x.shape[0] # read in N, C, H, W\n","    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n","\n","def test_flatten():\n","    x = torch.arange(12).view(2, 1, 3, 2)\n","    print('Before flattening: ', x)\n","    print('After flattening: ', flatten(x))\n","\n","test_flatten()"]},{"cell_type":"markdown","metadata":{"tags":["pdf-ignore"],"id":"35bygSdyU0Pb"},"source":["### Barebones PyTorch: Two-Layer Network\n","\n","Здесь мы определяем функцию `two_layer_fc`, которая выполняет прямой проход двухуровневой полносвязной сети ReLU для пакета данных изображения. После определения прямого прохода мы проверяем, что он не дает сбоев и выдает выходные данные правильной формы, пропуская нули через сеть.\n","\n","Вам не нужно писать здесь какой-либо код, но важно, чтобы вы прочитали и поняли реализацию."]},{"cell_type":"code","execution_count":15,"metadata":{"tags":["pdf-ignore-input"],"id":"7f0P5zlRU0Pb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656677344312,"user_tz":-240,"elapsed":8,"user":{"displayName":"Andrey Andrey","userId":"10427328636042614556"}},"outputId":"ae1c750c-0c67-4dad-8046-d9d998856def"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 10])\n"]}],"source":["import torch.nn.functional as F  # полезные функции без сохранения состояния\n","\n","def two_layer_fc(x, params):\n","    \"\"\"\n","    A fully-connected neural networks; the architecture is:\n","    NN is fully connected -> ReLU -> fully connected layer.\n","    Note that this function only defines the forward pass; \n","    PyTorch will take care of the backward pass for us.\n","    \n","    The input to the network will be a minibatch of data, of shape\n","    (N, d1, ..., dM) where d1 * ... * dM = D. The hidden layer will have H units,\n","    and the output layer will produce scores for C classes.\n","    \n","    Inputs:\n","    - x: A PyTorch Tensor of shape (N, d1, ..., dM) giving a minibatch of\n","      input data.\n","    - params: A list [w1, w2] of PyTorch Tensors giving weights for the network;\n","      w1 has shape (D, H) and w2 has shape (H, C).\n","    \n","    Returns:\n","    - scores: A PyTorch Tensor of shape (N, C) giving classification scores for\n","      the input data x.\n","    \"\"\"\n","    # first we flatten the image\n","    x = flatten(x)  # shape: [batch_size, C x H x W]\n","    \n","    w1, w2 = params\n","    \n","    # Прямой проход: вычисление предсказанного y с использованием операций с тензорами. \n","    # Поскольку w1 и w2 имеют require_grad=True, \n","    # операции с этими тензорами заставят PyTorch построить вычислительный граф, \n","    # позволяющий автоматически вычислять градиенты.\n","    # Поскольку мы больше не реализуем обратный проход вручную, нам не нужно сохранять ссылки на промежуточные значения. \n","    # вы также можете использовать `.clamp(min=0)`, что эквивалентно F.relu()\n","\n","    x = F.relu(x.mm(w1))\n","    x = x.mm(w2)\n","    return x\n","    \n","\n","def two_layer_fc_test():\n","    hidden_layer_size = 42\n","    x = torch.zeros((64, 50), dtype=dtype)  # minibatch size 64, feature dimension 50\n","    w1 = torch.zeros((50, hidden_layer_size), dtype=dtype)\n","    w2 = torch.zeros((hidden_layer_size, 10), dtype=dtype)\n","    scores = two_layer_fc(x, [w1, w2])\n","    print(scores.size())  # you should see [64, 10]\n","\n","two_layer_fc_test()"]},{"cell_type":"markdown","metadata":{"id":"bnRswhuvU0Pb"},"source":["### Barebones PyTorch: Three-Layer ConvNet\n","\n","Здесь вы завершите реализацию функции `three_layer_convnet`, которая будет выполнять прямой проход трехслойной сверточной сети. Как и выше, мы можем сразу протестировать нашу реализацию, пропустив нули по сети. Сеть должна иметь следующую архитектуру:\n","\n","1. Сверточный слой (со смещением) с фильтрами `channel_1`, каждый из которых имеет форму `KW1 x KH1`, и zero-padding = 2 \n","2. Нелинейность ReLU \n","3. Сверточный слой (со смещением) с фильтрами `channel_2`, каждый с формой `KW2 x KH2` и zero-padding = 1 \n","4. Нелинейность ReLU \n","5. Полносвязный слой со смещением, дающий оценки для классов C.\n","\n","\n","Обратите внимание, что у нас нет **активации softmax** здесь после нашего полносвязного слоя: это потому, что потеря перекрестной энтропии PyTorch выполняет активацию softmax для вас, и объединение этого шага делает вычисления более эффективными.\n","\n","**HINT**: Для сверток: http://pytorch.org/docs/stable/nn.html#torch.nn.functional.conv2d; обратите внимание на формы сверточных фильтров!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fj3uchkiU0Pc"},"outputs":[],"source":["def three_layer_convnet(x, params):\n","    \"\"\"\n","    Performs the forward pass of a three-layer convolutional network with the\n","    architecture defined above.\n","\n","    Inputs:\n","    - x: A PyTorch Tensor of shape (N, 3, H, W) giving a minibatch of images\n","    - params: A list of PyTorch Tensors giving the weights and biases for the\n","      network; should contain the following:\n","      - conv_w1: PyTorch Tensor of shape (channel_1, 3, KH1, KW1) giving weights\n","        for the first convolutional layer\n","      - conv_b1: PyTorch Tensor of shape (channel_1,) giving biases for the first\n","        convolutional layer\n","      - conv_w2: PyTorch Tensor of shape (channel_2, channel_1, KH2, KW2) giving\n","        weights for the second convolutional layer\n","      - conv_b2: PyTorch Tensor of shape (channel_2,) giving biases for the second\n","        convolutional layer\n","      - fc_w: PyTorch Tensor giving weights for the fully-connected layer. Can you\n","        figure out what the shape should be?\n","      - fc_b: PyTorch Tensor giving biases for the fully-connected layer. Can you\n","        figure out what the shape should be?\n","    \n","    Returns:\n","    - scores: PyTorch Tensor of shape (N, C) giving classification scores for x\n","    \"\"\"\n","    conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b = params\n","    scores = None\n","    ################################################################################\n","    # TODO: Implement the forward pass for the three-layer ConvNet.                #\n","    ################################################################################\n","    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","  \n","    # (input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) → Tensor\n","    conv_1 = F.conv2d(x,conv_w1,conv_b1,padding = 2)\n","    conv_1 = F.relu(conv_1)\n","\n","    conv_2 = F.conv2d(conv_1, conv_w2, conv_b2, padding = 1)\n","    conv_2 = F.relu(conv_2)\n","\n","    conv_2 = conv_2.view(conv_2.shape[0], -1)\n","    scores = conv_2.mm(fc_w) + fc_b  # (N, channel_2*H2*W2 ) x (channel_2*H2*W2, 10)\n","\n","    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","    ################################################################################\n","    #                                 END OF YOUR CODE                             #\n","    ################################################################################\n","    return scores"]},{"cell_type":"markdown","metadata":{"id":"VDiHq42uU0Pc"},"source":["После определения прямого прохода ConvNet выше запустите следующую ячейку, чтобы проверить свою реализацию. \n","\n","Когда вы запускаете эту функцию, оценки должны иметь форму (64, 10)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"barebones_output_shape","tags":["pdf-ignore-input"],"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656659844128,"user_tz":-240,"elapsed":10,"user":{"displayName":"Andrey Andrey","userId":"10427328636042614556"}},"outputId":"1f20f592-957b-4112-ba2d-73fb069f75cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 10])\n"]}],"source":["def three_layer_convnet_test():\n","    x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n","\n","    conv_w1 = torch.zeros((6, 3, 5, 5), dtype=dtype)  # [out_channel, in_channel, kernel_H, kernel_W]\n","    conv_b1 = torch.zeros((6,))  # out_channel\n","    conv_w2 = torch.zeros((9, 6, 3, 3), dtype=dtype)  # [out_channel, in_channel, kernel_H, kernel_W]\n","    conv_b2 = torch.zeros((9,))  # out_channel\n","\n","    # you must calculate the shape of the tensor after two conv layers, before the fully-connected layer\n","    fc_w = torch.zeros((9 * 32 * 32, 10))\n","    fc_b = torch.zeros(10)\n","\n","    scores = three_layer_convnet(x, [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b])\n","    print(scores.size())  # you should see [64, 10]\n","three_layer_convnet_test()"]},{"cell_type":"markdown","metadata":{"id":"fvrAw0CBU0Pd"},"source":["### Barebones PyTorch: Initialization\n","Давайте напишем пару служебных методов для инициализации весовых матриц для наших моделей.\n","\n","- `random_weight(shape)` инициализирует весовой тензор методом нормализации Кайминга. \n","- `zero_weight(shape)` инициализирует весовой тензор всеми нулями. Полезно для создания экземпляров параметров смещения. \n","\n","Функция `random_weight` использует нормальный метод инициализации Kaiming, описанный в: \n","He et al, *Delving Deep in Rectifiers: Surpassing Human-Level Performance on ImageNet Classification*, ICCV 2015, https://arxiv.org/abs/1502.01852"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["pdf-ignore-input"],"id":"0tu3dnCJU0Pd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656661017725,"user_tz":-240,"elapsed":11777,"user":{"displayName":"Andrey Andrey","userId":"10427328636042614556"}},"outputId":"3f557e8e-8ec7-451b-9491-6a7b6a552a63"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.5858, -0.0562,  0.9618, -0.9284,  0.0144],\n","        [ 0.0816,  1.1724,  0.6152,  0.3826,  0.2840],\n","        [ 0.4542, -0.5675,  0.4305, -0.9298,  1.8583]], device='cuda:0',\n","       requires_grad=True)"]},"metadata":{},"execution_count":9}],"source":["def random_weight(shape):\n","    \"\"\"\n","    Создавать случайные тензоры для весов; установка required_grad=True означает, \n","    что мы хотим вычислить градиенты для этих тензоров во время обратного прохода. \n","    Мы используем нормализацию Kaiming He: sqrt(2/fan_in)\n","    \"\"\"\n","    if len(shape) == 2:  # FC weight\n","        fan_in = shape[0]\n","    else:\n","        fan_in = np.prod(shape[1:]) # conv weight [out_channel, in_channel, kH, kW]\n","    # randn — стандартный генератор нормального распределения.\n","    w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / fan_in)\n","    w.requires_grad = True\n","    return w\n","\n","def zero_weight(shape):\n","    return torch.zeros(shape, device=device, dtype=dtype, requires_grad=True)\n","\n","# create a weight of shape [3 x 5]\n","# you should see the type `torch.cuda.FloatTensor` if you use GPU. \n","# Otherwise it should be `torch.FloatTensor`\n","random_weight((3, 5))"]},{"cell_type":"markdown","metadata":{"id":"x5qxZj9tU0Pe"},"source":["### Barebones PyTorch: Check Accuracy\n","При обучении модели мы будем использовать следующую функцию, чтобы проверить точность нашей модели на обучающих или проверочных наборах. \n","\n","При проверке точности нам не нужно вычислять какие-либо градиенты; в результате нам не нужен PyTorch для построения вычислительного графика при вычислении оценок. Чтобы предотвратить построение графика, мы ограничиваем наши вычисления контекстным менеджером `torch.no_grad()`."]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["pdf-ignore-input"],"id":"vxfa4fBZU0Pe"},"outputs":[],"source":["def check_accuracy_part2(loader, model_fn, params):\n","    \"\"\"\n","    Check the accuracy of a classification model.\n","    \n","    Inputs:\n","    - loader: A DataLoader for the data split we want to check\n","    - model_fn: A function that performs the forward pass of the model,\n","      with the signature scores = model_fn(x, params)\n","    - params: List of PyTorch Tensors giving parameters of the model\n","    \n","    Returns: Nothing, but prints the accuracy of the model\n","    \"\"\"\n","    split = 'val' if loader.dataset.train else 'test'\n","    print('Checking accuracy on the %s set' % split)\n","    num_correct, num_samples = 0, 0\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.int64)\n","            scores = model_fn(x, params)\n","            _, preds = scores.max(1)\n","            num_correct += (preds == y).sum()\n","            num_samples += preds.size(0)\n","        acc = float(num_correct) / num_samples\n","        print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))"]},{"cell_type":"markdown","metadata":{"id":"APhW_6TUU0Pf"},"source":["### BareBones PyTorch: Training Loop\n","Теперь мы можем настроить базовый тренировочный цикл для обучения нашей сети. Мы будем обучать модель, используя стохастический градиентный спуск без импульса. Мы будем использовать `torch.functional.cross_entropy` для вычисления потерь; вы можете [прочитать об этом здесь](http://pytorch.org/docs/stable/nn.html#cross-entropy). \n","\n","Цикл обучения принимает на вход функцию нейронной сети, список инициализированных параметров (`[w1, w2]` в нашем примере) и скорость обучения."]},{"cell_type":"code","execution_count":null,"metadata":{"tags":["pdf-ignore-input"],"id":"ak1mDo7pU0Pf"},"outputs":[],"source":["def train_part2(model_fn, params, learning_rate):\n","    \"\"\"\n","    Train a model on CIFAR-10.\n","    \n","    Inputs:\n","    - model_fn: A Python function that performs the forward pass of the model.\n","      It should have the signature scores = model_fn(x, params) where x is a\n","      PyTorch Tensor of image data, params is a list of PyTorch Tensors giving\n","      model weights, and scores is a PyTorch Tensor of shape (N, C) giving\n","      scores for the elements in x.\n","    - params: List of PyTorch Tensors giving weights for the model\n","    - learning_rate: Python scalar giving the learning rate to use for SGD\n","    \n","    Returns: Nothing\n","    \"\"\"\n","    for t, (x, y) in enumerate(loader_train):\n","        # Move the data to the proper device (GPU or CPU)\n","        x = x.to(device=device, dtype=dtype)\n","        y = y.to(device=device, dtype=torch.long)\n","\n","        # Forward pass: compute scores and loss\n","        scores = model_fn(x, params)\n","        loss = F.cross_entropy(scores, y)\n","\n","        # Обратный проход: PyTorch определяет, какие тензоры в вычислительном \n","        # графе имеют require_grad=True, и использует обратное распространение \n","        # для вычисления градиента потерь по отношению к этим тензорам и сохраняет \n","        # градиенты в атрибуте .grad каждого тензора.\n","        loss.backward()\n","\n","        # Обновить параметры. Мы не хотим выполнять обратное \n","        # распространение через обновления параметров, поэтому мы ограничиваем обновления контекстным менеджером torch.no_grad(),\n","        # чтобы предотвратить построение вычислительного графа.\n","        with torch.no_grad():\n","            for w in params:\n","                w -= learning_rate * w.grad\n","\n","                # Вручную обнулите градиенты после запуска обратного прохода\n","                w.grad.zero_()\n","\n","        if t % print_every == 0:\n","            print('Iteration %d, loss = %.4f' % (t, loss.item()))\n","            check_accuracy_part2(loader_val, model_fn, params)\n","            print()"]},{"cell_type":"markdown","metadata":{"id":"G9ZS56M-U0Pf"},"source":["### BareBones PyTorch: Train a Two-Layer Network\n","Теперь мы готовы запустить обучающий цикл. Нам нужно явно выделить тензоры для полносвязных весов, `w1` и `w2`. \n","\n","Каждая мини-партия CIFAR содержит 64 примера, поэтому форма тензора — `[64, 3, 32, 32]`. \n","\n","После выравнивания форма `x` должна быть `[64, 3 * 32 * 32]`. Это будет размер первого измерения `w1`. Второе измерение `w1` — это размер скрытого слоя, который также будет первым измерением `w2`. \n","\n","Наконец, выход сети представляет собой 10-мерный вектор, представляющий распределение вероятностей по 10 классам. \n","\n","Вам не нужно настраивать какие-либо гиперпараметры, но вы должны увидеть точность выше 40% после обучения в течение одной эпохи."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ySpYVwKCU0Pf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656669833705,"user_tz":-240,"elapsed":12877,"user":{"displayName":"Andrey Andrey","userId":"10427328636042614556"}},"outputId":"94da5080-c8d6-427f-a3d3-8e3861212bd9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 3.2562\n","Checking accuracy on the val set\n","Got 153 / 1000 correct (15.30%)\n","\n","Iteration 100, loss = 2.3759\n","Checking accuracy on the val set\n","Got 375 / 1000 correct (37.50%)\n","\n","Iteration 200, loss = 1.7924\n","Checking accuracy on the val set\n","Got 334 / 1000 correct (33.40%)\n","\n","Iteration 300, loss = 1.7461\n","Checking accuracy on the val set\n","Got 402 / 1000 correct (40.20%)\n","\n","Iteration 400, loss = 2.3272\n","Checking accuracy on the val set\n","Got 390 / 1000 correct (39.00%)\n","\n","Iteration 500, loss = 2.0704\n","Checking accuracy on the val set\n","Got 411 / 1000 correct (41.10%)\n","\n","Iteration 600, loss = 1.8602\n","Checking accuracy on the val set\n","Got 409 / 1000 correct (40.90%)\n","\n","Iteration 700, loss = 1.6342\n","Checking accuracy on the val set\n","Got 415 / 1000 correct (41.50%)\n","\n"]}],"source":["hidden_layer_size = 4000\n","learning_rate = 1e-2\n","\n","w1 = random_weight((3 * 32 * 32, hidden_layer_size))\n","w2 = random_weight((hidden_layer_size, 10))\n","\n","train_part2(two_layer_fc, [w1, w2], learning_rate)"]},{"cell_type":"markdown","metadata":{"id":"7J-rwMvTU0Pg"},"source":["### BareBones PyTorch: Training a ConvNet\n","\n","Ниже вы должны использовать функции, определенные выше, для обучения трехслойной сверточной сети на CIFAR. Сеть должна иметь следующую архитектуру: \n","\n","1. Сверточный слой (со смещением) с 32 фильтрами 5x5 с заполнением нулями 2 \n","2. ReLU \n","3. Сверточный слой (со смещением) с 16 фильтрами 3x3 с заполнением нулями 1 \n","4. ReLU \n","5. Полносвязный слой (со смещением) для вычисления оценок для 10 классов \n","\n","Вы должны инициализировать свои весовые матрицы, используя функцию random_weight, определенную выше, и вы должны инициализировать свои векторы смещения, используя описанную выше функцию `zero_weight`. \n","\n","Вам не нужно настраивать какие-либо гиперпараметры, но если все работает правильно, вы должны достичь точности выше 42% после одной эпохи."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"barebones_accuracy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656665015124,"user_tz":-240,"elapsed":13532,"user":{"displayName":"Andrey Andrey","userId":"10427328636042614556"}},"outputId":"e69185f5-7bfc-4cf0-8e80-c4818e2029f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 2.9123\n","Checking accuracy on the val set\n","Got 105 / 1000 correct (10.50%)\n","\n","Iteration 100, loss = 1.9749\n","Checking accuracy on the val set\n","Got 350 / 1000 correct (35.00%)\n","\n","Iteration 200, loss = 1.7172\n","Checking accuracy on the val set\n","Got 383 / 1000 correct (38.30%)\n","\n","Iteration 300, loss = 1.6311\n","Checking accuracy on the val set\n","Got 420 / 1000 correct (42.00%)\n","\n","Iteration 400, loss = 1.5742\n","Checking accuracy on the val set\n","Got 428 / 1000 correct (42.80%)\n","\n","Iteration 500, loss = 1.4530\n","Checking accuracy on the val set\n","Got 446 / 1000 correct (44.60%)\n","\n","Iteration 600, loss = 1.4023\n","Checking accuracy on the val set\n","Got 462 / 1000 correct (46.20%)\n","\n","Iteration 700, loss = 1.4064\n","Checking accuracy on the val set\n","Got 459 / 1000 correct (45.90%)\n","\n"]}],"source":["learning_rate = 3e-3\n","\n","channel_1 = 32\n","channel_2 = 16\n","\n","conv_w1 = None\n","conv_b1 = None\n","conv_w2 = None\n","conv_b2 = None\n","fc_w = None\n","fc_b = None\n","\n","################################################################################\n","# TODO: Initialize the parameters of a three-layer ConvNet.                    #\n","################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","conv_w1 = random_weight((channel_1, 3, 5, 5))\n","conv_b1 = zero_weight(channel_1)\n","\n","conv_w2 = random_weight((channel_2, channel_1, 3, 3))\n","conv_b2 = zero_weight(channel_2)\n","\n","fc_w = random_weight((channel_2*32*32, 10))\n","fc_b = zero_weight(10)\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                                 END OF YOUR CODE                             #\n","################################################################################\n","\n","params = [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b]\n","train_part2(three_layer_convnet, params, learning_rate)"]},{"cell_type":"markdown","metadata":{"id":"GSydsC5_U0Pg"},"source":["# Part III. PyTorch Module API\n","\n","Barebone PyTorch требует, чтобы мы вручную отслеживали все тензоры параметров. Это хорошо для небольших сетей с несколькими тензорами, но было бы крайне неудобно и подвержено ошибкам отслеживать десятки или сотни тензоров в больших сетях. \n","\n","PyTorch предоставляет API `nn.Module`, с помощью которого вы можете определять произвольные сетевые архитектуры, отслеживая при этом все доступные для вас параметры. Во второй части мы сами реализовали SGD. PyTorch также предоставляет пакет `torch.optim`, который реализует все распространенные оптимизаторы, такие как RMSProp, Adagrad и Adam. Он даже поддерживает приближенные методы второго порядка, такие как L-BFGS! Вы можете обратиться к [doc](http://pytorch.org/docs/master/optim.html) для получения точных спецификаций каждого оптимизатора.\n","\n","\n","Чтобы использовать API модуля, выполните следующие действия: \n","\n","1. Подкласс `nn.Module`. Дайте вашему сетевому классу интуитивно понятное имя, например TwoLayerFC. \n","\n","2. В конструкторе `__init__()` определите все необходимые слои как атрибуты класса. Объекты слоя, такие как `nn.Linear` и `nn.Conv2d`, сами по себе являются подклассами `nn.Module` и содержат обучаемые параметры, поэтому вам не нужно создавать необработанные тензоры самостоятельно. `nn.Module` будет отслеживать эти внутренние параметры для вас. Обратитесь к [doc](http://pytorch.org/docs/master/nn.html), чтобы узнать больше о десятках встроенных слоев. **Внимание**: не забудьте сначала вызвать `super().__init__()`! \n","\n","3. В методе `forward()` определите *соединение* вашей сети. Вы должны использовать атрибуты, определенные в `__init__`, как вызовы функций, которые принимают тензор в качестве входных данных и выводят \"преобразованный\" тензор. *Не* создавайте новые слои с изучаемыми параметрами в `forward()`! Все они должны быть объявлены заранее в `__init__`. \n","\n","После того, как вы определите свой подкласс модуля, вы можете создать его экземпляр как объект и вызвать его точно так же, как функцию прямой прохода NN в части II.\n","\n","### API модуля: двухуровневая сеть \n","Вот конкретный пример двухуровневой полносвязной сети:"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"0CBUaThlU0Pg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656678368840,"user_tz":-240,"elapsed":416,"user":{"displayName":"Andrey Andrey","userId":"10427328636042614556"}},"outputId":"37f69fda-f706-43b3-f4b6-32e802060f97"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 10])\n"]}],"source":["class TwoLayerFC(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super().__init__()\n","        # назначать объекты слоя атрибутам класса\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        # nn.init пакет содержит удобные методы инициализации\n","        # http://pytorch.org/docs/master/nn.html#torch-nn-init \n","        nn.init.kaiming_normal_(self.fc1.weight)\n","        self.fc2 = nn.Linear(hidden_size, num_classes)\n","        nn.init.kaiming_normal_(self.fc2.weight)\n","    \n","    def forward(self, x):\n","        # forward всегда определяет подключение\n","        x = flatten(x) # эту функцию сами определили выше в части 2.\n","        scores = self.fc2(F.relu(self.fc1(x)))\n","        return scores\n","\n","def test_TwoLayerFC():\n","    input_size = 50\n","    x = torch.zeros((64, input_size), dtype=dtype)  # minibatch size 64, feature dimension 50\n","    model = TwoLayerFC(input_size, 42, 10)\n","    scores = model(x)\n","    print(scores.size())  # you should see [64, 10]\n","test_TwoLayerFC()"]},{"cell_type":"markdown","metadata":{"id":"eClv4UJnU0Ph"},"source":["### Module API: Three-Layer ConvNet\n","\n","Теперь ваша очередь реализовать трехуровневую ConvNet, за которой следует полносвязный слой. Архитектура сети должна быть такой же, как и в части II: \n","\n","1. Сверточный слой с фильтрами 5x5 `channel_1` с заполнением нулями 2 \n","2. ReLU \n","3. Сверточный слой с фильтрами 3x3 `channel_2` с заполнением нулями 1 \n","4. ReLU \n","5. Полностью связанный слой с классами `num_classes` \n","\n","Вы должны инициализировать весовые матрицы модели, используя нормальный метод инициализации Кайминга.\n","\n"," **СОВЕТ**: http://pytorch.org/docs/stable/nn.html#conv2d \n"," \n","После реализации трехуровневой ConvNet функция `test_ThreeLayerConvNet` запустит вашу реализацию; он должен напечатать `(64, 10)` для формы выходных оценок."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"module_output_shape","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656670579684,"user_tz":-240,"elapsed":950,"user":{"displayName":"Andrey Andrey","userId":"10427328636042614556"}},"outputId":"3b33c749-798d-4416-952c-ffbf4e73fd97"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 10])\n"]}],"source":["class ThreeLayerConvNet(nn.Module):\n","    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n","        super().__init__()\n","        ########################################################################\n","        # TODO: Set up the layers you need for a three-layer ConvNet with the  #\n","        # architecture defined above.                                          #\n","        ########################################################################\n","        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","        '''\n","        conv5x5 -> relu -> conv3x3 -> relu -> fc \n","        '''\n","        self.conv1 = nn.Conv2d(in_channel, channel_1, (5,5), padding = (2,2), device = device ) # padding = \"same\" можно было так как у нас stride = 1\n","        self.conv2 = nn.Conv2d(channel_1, channel_2, (3,3), padding = \"same\", device = device )\n","        self.fc = nn.Linear(channel_2*32*32, 10, device = device)\n","\n","        # инициализация весов слоев\n","        nn.init.kaiming_normal_(self.conv1.weight)\n","        nn.init.kaiming_normal_(self.conv2.weight)\n","        nn.init.kaiming_normal_(self.fc.weight)\n","\n","        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        ########################################################################\n","        #                          END OF YOUR CODE                            #       \n","        ########################################################################\n","\n","    def forward(self, x):\n","        scores = None\n","        ########################################################################\n","        # TODO: Implement the forward function for a 3-layer ConvNet. you      #\n","        # should use the layers you defined in __init__ and specify the        #\n","        # connectivity of those layers in forward()                            #\n","        ########################################################################\n","        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","        x = x.to(device=device, dtype=dtype)\n","        conv_out = F.relu(self.conv2(F.relu(self.conv1(x)))) # для nn.ReLU: m = nn.ReLU   out = m(input)\n","        conv_out = conv_out.view(conv_out.shape[0], -1)\n","        scores = self.fc(conv_out)\n","        \n","        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","        ########################################################################\n","        #                             END OF YOUR CODE                         #\n","        ########################################################################\n","        return scores\n","\n","\n","def test_ThreeLayerConvNet():\n","    x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n","    model = ThreeLayerConvNet(in_channel=3, channel_1=12, channel_2=8, num_classes=10)\n","    scores = model(x)\n","    print(scores.size())  # you should see [64, 10]\n","test_ThreeLayerConvNet()"]},{"cell_type":"markdown","metadata":{"id":"LQDqCOr9U0Ph"},"source":["### Module API: Check Accuracy\n","Имея проверочный или тестовый набор, мы можем проверить точность классификации нейронной сети. \n","\n","Эта версия немного отличается от версии во второй части. Вы больше не передаете параметры вручную."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"tk3s1pNyU0Ph","executionInfo":{"status":"ok","timestamp":1656677298509,"user_tz":-240,"elapsed":432,"user":{"displayName":"Andrey Andrey","userId":"10427328636042614556"}}},"outputs":[],"source":["def check_accuracy_part34(loader, model):\n","    if loader.dataset.train:\n","        print('Checking accuracy on validation set')\n","    else:\n","        print('Checking accuracy on test set')   \n","    num_correct = 0\n","    num_samples = 0\n","    model.eval()  # установить модель в режим оценки\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.long)\n","            scores = model(x)\n","            _, preds = scores.max(1)\n","            num_correct += (preds == y).sum()\n","            num_samples += preds.size(0)\n","        acc = float(num_correct) / num_samples\n","        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"]},{"cell_type":"markdown","metadata":{"id":"vAY6ANX1U0Pi"},"source":["### Module API: Training Loop\n","Мы также используем немного другой тренировочный цикл. Вместо самостоятельного обновления значений весов мы используем объект Optimizer из пакета `torch.optim`, который абстрагирует понятие алгоритма оптимизации и предоставляет реализации большинства алгоритмов, обычно используемых для оптимизации нейронных сетей."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"HcG6WqZ4U0Pi","executionInfo":{"status":"ok","timestamp":1656677295275,"user_tz":-240,"elapsed":424,"user":{"displayName":"Andrey Andrey","userId":"10427328636042614556"}}},"outputs":[],"source":["def train_part34(model, optimizer, epochs=1):\n","    \"\"\"\n","    Train a model on CIFAR-10 using the PyTorch Module API.\n","    \n","    Inputs:\n","    - model: A PyTorch Module giving the model to train.\n","    - optimizer: An Optimizer object we will use to train the model\n","    - epochs: (Optional) A Python integer giving the number of epochs to train for\n","    \n","    Returns: Nothing, but prints model accuracies during training.\n","    \"\"\"\n","    model = model.to(device=device)  # move the model parameters to CPU/GPU\n","    for e in range(epochs):\n","        for t, (x, y) in enumerate(loader_train):\n","            model.train()  # put model to training mode\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.long)\n","\n","            scores = model(x)\n","            loss = F.cross_entropy(scores, y)\n","\n","        \n","            # Обнулите все градиенты для переменных, которые будет обновлять оптимизатор.\n","            optimizer.zero_grad()\n","\n","            # Это обратный проход: вычислить градиент потери по отношению к каждому параметру модели.\n","            loss.backward()\n","\n","            # Actually update the parameters of the model using the gradients\n","            # computed by the backwards pass.\n","            optimizer.step()\n","\n","            if t % print_every == 0:\n","                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n","                check_accuracy_part34(loader_val, model)\n","                print()"]},{"cell_type":"markdown","metadata":{"id":"vJS0HsPFU0Pi"},"source":["### Module API: Train a Two-Layer Network\n","Теперь мы готовы запустить обучающий цикл. В отличие от части II, мы больше не выделяем явно тензоры параметров. \n","\n","Просто передайте размер ввода, размер скрытого слоя и количество классов (т.е. размер вывода) конструктору `TwoLayerFC`.\n","\n","Вам также необходимо определить оптимизатор, который отслеживает все обучаемые параметры внутри `TwoLayerFC`. Вам не нужно настраивать какие-либо гиперпараметры, но вы должны увидеть точность модели выше 40% после обучения в течение одной эпохи."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q1lUjcpKU0Pj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656672560339,"user_tz":-240,"elapsed":12762,"user":{"displayName":"Andrey Andrey","userId":"10427328636042614556"}},"outputId":"999e3308-7d58-4a66-ef3f-9c695f7803ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 3.9317\n","Checking accuracy on validation set\n","Got 188 / 1000 correct (18.80)\n","\n","Iteration 100, loss = 2.0891\n","Checking accuracy on validation set\n","Got 352 / 1000 correct (35.20)\n","\n","Iteration 200, loss = 1.8417\n","Checking accuracy on validation set\n","Got 381 / 1000 correct (38.10)\n","\n","Iteration 300, loss = 1.8980\n","Checking accuracy on validation set\n","Got 414 / 1000 correct (41.40)\n","\n","Iteration 400, loss = 2.1986\n","Checking accuracy on validation set\n","Got 391 / 1000 correct (39.10)\n","\n","Iteration 500, loss = 1.5180\n","Checking accuracy on validation set\n","Got 445 / 1000 correct (44.50)\n","\n","Iteration 600, loss = 1.7388\n","Checking accuracy on validation set\n","Got 419 / 1000 correct (41.90)\n","\n","Iteration 700, loss = 1.8891\n","Checking accuracy on validation set\n","Got 422 / 1000 correct (42.20)\n","\n"]}],"source":["hidden_layer_size = 4000\n","learning_rate = 1e-2\n","model = TwoLayerFC(3 * 32 * 32, hidden_layer_size, 10)\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n","\n","train_part34(model, optimizer)"]},{"cell_type":"markdown","metadata":{"id":"7h0mHuB-U0Pj"},"source":["### Module API: Train a Three-Layer ConvNet\n","Теперь вы должны использовать API модуля для обучения трехуровневой сети ConvNet на CIFAR. Это должно выглядеть очень похоже на обучение двухслойной сети! Вам не нужно настраивать какие-либо гиперпараметры, но вы должны достичь выше 45% после обучения в течение одной эпохи. \n","\n","Вы должны обучить модель, используя стохастический градиентный спуск без импульса."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"module_accuracy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656672925468,"user_tz":-240,"elapsed":12988,"user":{"displayName":"Andrey Andrey","userId":"10427328636042614556"}},"outputId":"ba6f0b25-23de-4351-875f-333c408e25b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 3.0579\n","Checking accuracy on validation set\n","Got 122 / 1000 correct (12.20)\n","\n","Iteration 100, loss = 1.9414\n","Checking accuracy on validation set\n","Got 334 / 1000 correct (33.40)\n","\n","Iteration 200, loss = 1.8284\n","Checking accuracy on validation set\n","Got 381 / 1000 correct (38.10)\n","\n","Iteration 300, loss = 1.7455\n","Checking accuracy on validation set\n","Got 423 / 1000 correct (42.30)\n","\n","Iteration 400, loss = 1.4992\n","Checking accuracy on validation set\n","Got 419 / 1000 correct (41.90)\n","\n","Iteration 500, loss = 1.6114\n","Checking accuracy on validation set\n","Got 437 / 1000 correct (43.70)\n","\n","Iteration 600, loss = 1.3020\n","Checking accuracy on validation set\n","Got 434 / 1000 correct (43.40)\n","\n","Iteration 700, loss = 1.4912\n","Checking accuracy on validation set\n","Got 453 / 1000 correct (45.30)\n","\n"]}],"source":["learning_rate = 3e-3\n","channel_1 = 32\n","channel_2 = 16\n","\n","model = None\n","optimizer = None\n","################################################################################\n","# TODO: Instantiate your ThreeLayerConvNet model and a corresponding optimizer #\n","################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","model = ThreeLayerConvNet(3, channel_1, channel_2, 10)\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                                 END OF YOUR CODE                             \n","################################################################################\n","\n","train_part34(model, optimizer)"]},{"cell_type":"markdown","metadata":{"id":"GBbQ-Z63U0Pj"},"source":["\n","\n","Часть III представила API модуля PyTorch, который позволяет вам определять произвольные обучаемые слои и их связь. \n","\n","Для простых моделей, таких как стек слоев прямой связи, вам все равно нужно пройти 3 шага: подкласс `nn.Module`, назначить слои атрибутам класса в `__init__` и вызвать каждый слой один за другим в `forward()` . Есть ли более удобный способ? \n","\n","К счастью, PyTorch предоставляет модуль-контейнер под названием nn.Sequential, который объединяет вышеуказанные шаги в один. Он не такой гибкий, как `nn.Module`, потому что вы не можете указать более сложную топологию, чем стек с прямой связью, но этого достаточно для многих случаев использования. \n","\n","### Sequential API: двухуровневая сеть \n","\n","Давайте посмотрим, как переписать наш пример двухуровневой полносвязной сети с помощью `nn.Sequential` и обучить ее, используя описанный выше цикл обучения. Опять же, вам не нужно настраивать здесь какие-либо гиперпараметры, но вы должны достичь точности выше 40% после одной эпохи обучения."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"iTg6vjZvU0Pk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656677463191,"user_tz":-240,"elapsed":111829,"user":{"displayName":"Andrey Andrey","userId":"10427328636042614556"}},"outputId":"af71dda0-26ea-4364-9ae0-dca9bdb8f949"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 2.3374\n","Checking accuracy on validation set\n","Got 149 / 1000 correct (14.90)\n","\n","Iteration 100, loss = 1.5450\n","Checking accuracy on validation set\n","Got 371 / 1000 correct (37.10)\n","\n","Iteration 200, loss = 1.8890\n","Checking accuracy on validation set\n","Got 387 / 1000 correct (38.70)\n","\n","Iteration 300, loss = 2.2270\n","Checking accuracy on validation set\n","Got 416 / 1000 correct (41.60)\n","\n","Iteration 400, loss = 2.0906\n","Checking accuracy on validation set\n","Got 404 / 1000 correct (40.40)\n","\n","Iteration 500, loss = 1.5994\n","Checking accuracy on validation set\n","Got 433 / 1000 correct (43.30)\n","\n","Iteration 600, loss = 1.7978\n","Checking accuracy on validation set\n","Got 455 / 1000 correct (45.50)\n","\n","Iteration 700, loss = 1.5488\n","Checking accuracy on validation set\n","Got 412 / 1000 correct (41.20)\n","\n"]}],"source":["# Нам нужно обернуть функцию `flatten` в модуль, чтобы сложить ее в nn.Sequential\n","class Flatten(nn.Module):\n","    def forward(self, x):\n","        return flatten(x)\n","\n","hidden_layer_size = 4000\n","learning_rate = 1e-2\n","\n","model = nn.Sequential(\n","    Flatten(),\n","    nn.Linear(3 * 32 * 32, hidden_layer_size),\n","    nn.ReLU(),\n","    nn.Linear(hidden_layer_size, 10),\n",")\n","\n","# you can use Nesterov momentum in optim.SGD\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n","                     momentum=0.9, nesterov=True)\n","\n","train_part34(model, optimizer)"]},{"cell_type":"markdown","metadata":{"id":"KPuInqNlU0Pk"},"source":["### Sequential API: Three-Layer ConvNet\n","\n","Здесь вы должны использовать `nn.Sequential` для определения и обучения трехслойной ConvNet с той же архитектурой, которую мы использовали в части III: \n","\n","1. Сверточный слой (со смещением) с 32 фильтрами 5x5, с нулевым заполнением 2 \n","2. ReLU \n","3. Сверточный слой (со смещением) с 16 фильтрами 3x3 с заполнением нулями 1 \n","4. ReLU \n","5. Полносвязный слой (со смещением) для вычисления оценок для 10 классов. \n","\n","Вы должны инициализировать свои весовые матрицы с помощью функции `random_weight`. определено выше, и вы должны инициализировать свои векторы смещения, используя функцию `zero_weight` выше. \n","\n","Вы должны оптимизировать свою модель, используя стохастический градиентный спуск с импульсом Нестерова 0.9. \n","\n","Опять же, вам не нужно настраивать какие-либо гиперпараметры, но вы должны увидеть точность выше 55% после одной эпохи обучения."]},{"cell_type":"code","execution_count":33,"metadata":{"id":"sequential_accuracy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656681391862,"user_tz":-240,"elapsed":78789,"user":{"displayName":"Andrey Andrey","userId":"10427328636042614556"}},"outputId":"3a3493a6-f551-43d4-e733-67ac5364060d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 2.3152\n","Checking accuracy on validation set\n","Got 150 / 1000 correct (15.00)\n","\n","Iteration 100, loss = 1.4049\n","Checking accuracy on validation set\n","Got 444 / 1000 correct (44.40)\n","\n","Iteration 200, loss = 1.3450\n","Checking accuracy on validation set\n","Got 492 / 1000 correct (49.20)\n","\n","Iteration 300, loss = 1.2861\n","Checking accuracy on validation set\n","Got 511 / 1000 correct (51.10)\n","\n","Iteration 400, loss = 1.1766\n","Checking accuracy on validation set\n","Got 515 / 1000 correct (51.50)\n","\n","Iteration 500, loss = 1.2398\n","Checking accuracy on validation set\n","Got 522 / 1000 correct (52.20)\n","\n","Iteration 600, loss = 1.2636\n","Checking accuracy on validation set\n","Got 570 / 1000 correct (57.00)\n","\n","Iteration 700, loss = 1.1380\n","Checking accuracy on validation set\n","Got 573 / 1000 correct (57.30)\n","\n"]}],"source":["channel_1 = 32\n","channel_2 = 16\n","learning_rate = 1e-2\n","\n","model = None\n","optimizer = None\n","\n","################################################################################\n","# TODO: Rewrite the 3-layer ConvNet with bias from Part III with the           #\n","# Sequential API.                                                              #\n","################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","model = nn.Sequential(\n","        nn.Conv2d(3, channel_1, 5, padding = 2),\n","        nn.ReLU(),\n","        nn.Conv2d(channel_1, channel_2, 3, padding = 1),\n","        nn.ReLU(),\n","        Flatten(),\n","        nn.Linear(channel_2*32*32,10)\n","        ).to(device)\n","\n","'''\n","apply(fn): рекурсивно применяется fn к каждому подмодулю (возвращенному функцией .children()), \n","а также к самому себе. Типичное использование включает инициализацию параметров модели.\n","'''\n","def weights_init(m):\n","    if isinstance(m, nn.Conv2d): # можно было и без условия на сверточный слой, но это для наглядности\n","        #nn.init.kaiming_normal_(m.weight.data)\n","        nn.init.kaiming_uniform_(m.weight.data)\n","        nn.init.zeros_(m.bias.data) \n","    if isinstance(m, nn.Linear):\n","        #nn.init.kaiming_normal_(m.weight.data)\n","        nn.init.kaiming_uniform_(m.weight.data)\n","        nn.init.zeros_(m.bias.data)\n","    \n","#model.apply(weights_init) # инициализация весов. C инициализацией по умолчанию точность выше. WTF. \n","# https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/linear.py#L44-L48 код инициализации по умолчанию. см reset_parameters(self)\n","# https://discuss.pytorch.org/t/whats-the-default-initialization-methods-for-layers/3157/19 # про не задокументированную инициализацию\n","\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                                 END OF YOUR CODE                             \n","################################################################################\n","\n","train_part34(model, optimizer)"]},{"cell_type":"code","source":["for i in model.children():\n","  print(i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YG4Fg1LO0jPp","executionInfo":{"status":"ok","timestamp":1656682634453,"user_tz":-240,"elapsed":511,"user":{"displayName":"Andrey Andrey","userId":"10427328636042614556"}},"outputId":"e0552a3e-697f-4c00-f8ff-ae9f8a1f3328"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","ReLU()\n","Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","ReLU()\n","Flatten()\n","Linear(in_features=16384, out_features=10, bias=True)\n"]}]},{"cell_type":"markdown","metadata":{"id":"g02wKEZoU0Pk"},"source":["# Part V. CIFAR-10 open-ended challenge\n","\n","В этом разделе вы можете поэкспериментировать с любой архитектурой ConvNet на CIFAR-10, которая вам нравится. \n","\n","Теперь ваша задача — поэкспериментировать с архитектурами, гиперпараметрами, функциями потерь и оптимизаторами, чтобы обучить модель, которая достигает **по крайней мере 70%** точности на **валидационном** наборе CIFAR-10 в течение 10 эпох. Вы можете использовать функции check_accuracy и train сверху. Вы можете использовать либо `nn.Module`, либо `nn.Sequential` API.\n","\n","Опишите, что вы сделали в конце этой тетради. \n","\n","Вот официальная документация API для каждого компонента. Одно замечание: то, что мы называем в классе «пространственной пакетной нормой», в PyTorch называется «BatchNorm2D». \n","\n","* Слои в пакете torch.nn: http://pytorch.org/docs/stable/nn.html \n","* Активации: http://pytorch.org/docs/stable/nn.html#non-linear-activations \n","* Функции потерь : http://pytorch.org/docs/stable/nn.html#loss-functions \n","* Оптимизаторы: http://pytorch.org/docs/stable/optim.html\n","\n","\n","### Что вы можете попробовать: \n","- **Размер фильтра**: Выше мы использовали 5x5; будут ли фильтры меньшего размера более эффективными? \n","- **Количество фильтров**: выше мы использовали 32 фильтра. Больше или меньше делают лучше? \n","- **Pooling против пошаговой свертки**: вы используете максимальное объединение или только пошаговые свертки? \n","- **Пакетная нормализация**: попробуйте добавить пространственную пакетную нормализацию после сверточных слоев и ванильную пакетную нормализацию после аффинных слоев. Ваши сети обучаются быстрее? \n","- **Сетевая архитектура**: приведенная выше сеть имеет три уровня обучаемых параметров. Можете ли вы добиться большего успеха с глубокой сетью? Хорошие архитектуры, которые можно попробовать, включают: \n","- [conv-relu-pool]xN -> [affine]xM -> [softmax или SVM] \n","- [conv-relu-conv-relu-pool]xN -> [affine]xM -> [ softmax или SVM] \n","- [batchnorm-relu-conv]xN -> [affine]xM -> [softmax или SVM] \n","- **Global Average Pooling**: вместо выравнивания (flattening) и последующего создания нескольких аффинных слоев выполняйте свертки до тех пор, пока ваше изображение становится маленьким (7x7 или около того), а затем выполняет операцию average pooling, чтобы получить изображение изображения 1x1 (1, 1, Filter#), которое затем преобразуется в вектор (Filter#). Это используется в [Google's Inception Network] (https://arxiv.org/abs/1512.00567) (см. Таблицу 1 для их архитектуры). \n","- **Регуляризация**: добавьте регуляризацию веса l2 или, возможно, используйте Dropout.\n","\n","\n","\n","### Tips for training\n","Для каждой сетевой архитектуры, которую вы пробуете, вы должны настроить скорость обучения и другие гиперпараметры. При этом следует помнить о нескольких важных вещах: \n","- Если параметры работают хорошо, вы должны увидеть улучшение в течение нескольких сотен итераций \n","- Помните подход от грубой к точной настройке гиперпараметров: начните с тестирования большого диапазона гиперпараметров всего за несколько итераций обучения, чтобы найти комбинации параметров, которые вообще работают. \n","- После того, как вы нашли несколько наборов параметров, которые, по-видимому, работают, выполните более тщательный поиск по этим параметрам. Возможно, вам придется тренироваться для большего количества эпох. \n","- Вам следует использовать проверочный набор для поиска гиперпараметров и сохранить тестовый набор для оценки вашей архитектуры по лучшим параметрам, выбранным проверочным набором.\n","\n","### Going above and beyond (делая все возможное)\n","Если вы чувствуете себя авантюрным, есть много других особенностей, которые вы можете реализовать, чтобы попытаться улучшить свою производительность. Вы **не обязаны** реализовывать что-либо из этого, но не пропустите веселье, если у вас есть время! \n","\n","- Альтернативные оптимизаторы: вы можете попробовать Adam, Adagrad, RMSprop и т. д. \n","- Альтернативные функции активации, такие как Leaky ReLU, PReLU, ELU или MaxOut. \n","- Ансамбли моделей \n","- Увеличение данных \n","- Новые архитектуры \n","  - [ResNets] (https://arxiv.org/abs/1512.03385), где входные данные из предыдущего слоя добавляются к выходным. \n","  - [DenseNets] (https://arxiv.org/abs/1608.06993), где входные данные предыдущих слоев объединяются вместе. \n","  - [В этом блоге есть подробный обзор] (https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)\n","\n","### Have fun and happy training! "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"open_ended_accuracy"},"outputs":[],"source":["################################################################################\n","# TODO:                                                                        #         \n","# Experiment with any architectures, optimizers, and hyperparameters.          #\n","# Achieve AT LEAST 70% accuracy on the *validation set* within 10 epochs.      #\n","#                                                                              #\n","# Note that you can use the check_accuracy function to evaluate on either      #\n","# the test set or the validation set, by passing either loader_test or         #\n","# loader_val as the second argument to check_accuracy. You should not touch    #\n","# the test set until you have finished your architecture and  hyperparameter   #\n","# tuning, and only run the test set once at the end to report a final value.   #\n","################################################################################\n","model = None\n","optimizer = None\n","\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","pass\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                                 END OF YOUR CODE                             \n","################################################################################\n","\n","# You should get at least 70% accuracy\n","train_part34(model, optimizer, epochs=10)"]},{"cell_type":"markdown","metadata":{"tags":["pdf-inline"],"id":"BX9YXwRyU0Pl"},"source":["## Describe what you did \n","\n","В ячейке ниже вы должны написать объяснение того, что вы сделали, любые дополнительные функции, которые вы реализовали, и/или любые графики, которые вы сделали в процессе обучения и оценки вашей сети."]},{"cell_type":"markdown","metadata":{"tags":["pdf-inline"],"id":"XuN2lQIkU0Pl"},"source":["TODO: Describe what you did"]},{"cell_type":"markdown","metadata":{"id":"Fp-wQ31LU0Pl"},"source":["## Test set -- run this only once\n","\n","Теперь, когда мы получили результат, которым мы довольны, мы тестируем нашу окончательную модель на тестовом наборе (которую вы должны сохранить в best_model). Подумайте, как это соотносится с точностью вашего проверочного набора."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UzQEn1aMU0Pl"},"outputs":[],"source":["best_model = model\n","check_accuracy_part34(loader_test, best_model)"]}],"metadata":{"colab":{"name":"PyTorch.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}